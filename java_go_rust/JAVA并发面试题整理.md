# JAVA 并发面试题整理

1. 进程、线程、协程

  - 进程是操作系统资源分配的基本单位，它包含了程序代码、数据以及运行时系统资源（如打开的文件、网络连接等），可以看作是一个独立的运行环境。进程之间相互独立，每个进程都有自己的地址空间、工作栈和其他操作系统资源。不同进程之间通信需要使用进程间通信机制（IPC）。

  - 线程是进程内的独立执行流，线程共享进程的地址空间和资源，但拥有自己的堆栈和寄存器。多个线程可以同时在同一个进程内执行不同的任务，它们之间可以通过共享内存等方式进行通信。

  - 协程是一种用户态的轻量级线程，也被称为“微线程”。协程不依赖于操作系统的调度，而是由用户程序自行管理调度，因此切换成本非常低。协程可以看作是一种特殊的子例程，不同的是它可以暂停执行，并且可以从上次暂停的位置继续执行。协程适用于高并发、高性能和复杂的应用场景，例如网络编程、Web框架等。

2. 并行与并发

  - **并发**：两个及两个以上的作业在同一 **时间段** 内执行。
  - **并行**：两个及两个以上的作业在同一 **时刻** 执行。

3. 同步与异步

  - **同步**：发出一个调用之后，在没有得到结果之前， 该调用就不可以返回，一直等待。
  - **异步**：调用在发出之后，不用等待返回结果，该调用直接返回。

4. 为什么要使用多线程

  使用多线程可以提高程序的并发性和响应能力，也可以充分利用计算机的多核处理器来提高程序的运行效率。在单线程情况下，当程序执行一个耗时的操作时，整个程序都会被阻塞，无法继续执行其他任务。而多线程可以使得多个任务同时执行，即使其中某些任务阻塞了，其他任务也仍然可以继续执行，从而提高了程序的并发性和响应能力。此外，如果程序需要进行一些并行计算，多线程也可以将这些计算任务分配到不同的线程上并行执行，从而显著提高程序的运行效率。

5. 使用多线程可能带来的问题？

  并发编程的目的就是为了能提高程序的执行效率提高程序运行速度，但是并发编程并不总是能提高程序运行速度的，而且并发编程可能会遇到很多问题，比如：内存泄漏、死锁、线程不安全等等。

6. 如何理解线程安全和不安全？

  线程安全和不安全是在多线程环境下对于同一份数据的访问是否能够保证其正确性和一致性的描述。

  - 线程安全指的是在多线程环境下，对于同一份数据，不管有多少个线程同时访问，都能保证这份数据的正确性和一致性。
  - 线程不安全则表示在多线程环境下，对于同一份数据，多个线程同时访问时可能会导致数据混乱、错误或者丢失。

7. Java线程的生命周期和状态？

  Java 线程在运行的生命周期中的指定时刻只可能处于下面 6 种不同状态的其中一个状态：

  - NEW: 初始状态，线程被创建出来但没有被调用 `start()` 。
  - RUNNABLE: 运行状态，线程被调用了 `start()`等待运行的状态。
  - BLOCKED：阻塞状态，需要等待锁释放。
  - WAITING：等待状态，表示该线程需要等待其他线程做出一些特定动作（通知或中断）。
  - TIME_WAITING：超时等待状态，可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。
  - TERMINATED：终止状态，表示该线程已经运行完毕。

8. 什么是线程上下文切换？

  线程在执行过程中会有自己的运行条件和状态（也称上下文），比如上文所说到过的程序计数器，栈信息等。当出现如下情况的时候，线程会从占用 CPU 状态中退出。

  - 主动让出 CPU，比如调用了 `sleep()`, `wait()` 等。
  - 时间片用完，因为操作系统要防止一个线程或者进程长时间占用 CPU 导致其他线程或者进程饿死。
  - 调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。
  - 被终止或结束运行

  这其中前三种都会发生线程切换，线程切换意味着需要保存当前线程的上下文，留待线程下次占用 CPU 的时候恢复现场。并加载下一个将要占用 CPU 的线程上下文。这就是所谓的 **上下文切换**。

  上下文切换是现代操作系统的基本功能，因其每次需要保存信息恢复信息，这将会占用 CPU，内存等系统资源进行处理，也就意味着效率会有一定损耗，如果频繁切换就会造成整体效率低下。

9. 产生死锁的必要条件

  - 互斥条件：该资源任意一个时刻只由一个线程占用。
  - 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
  - 不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
  - 循环等待条件:若干线程之间形成一种头尾相接的循环等待资源关系。

10. 如何预防死锁

	- **破坏请求与保持条件**：一次性申请所有的资源。

	- **破坏不剥夺条件**：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。

	- **破坏循环等待条件**：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。

11. 如何避免死锁

	避免死锁就是在资源分配时，借助于算法（比如银行家算法）对资源分配进行计算评估，使其进入安全状态。

12. sleep()方法和wait()方法对比

	**共同点**：两者都可以暂停线程的执行。

	**区别**：

	- **`sleep()` 方法没有释放锁，而 `wait()` 方法释放了锁** 。
	- `wait()` 通常被用于线程间交互/通信，`sleep()`通常被用于暂停执行。
	- `wait()` 方法被调用后，线程不会自动苏醒，需要别的线程调用同一个对象上的 `notify()`或者 `notifyAll()` 方法。`sleep()`方法执行完成后，线程会自动苏醒，或者也可以使用 `wait(long timeout)` 超时后线程会自动苏醒。
	- `sleep()` 是 `Thread` 类的静态本地方法，`wait()` 则是 `Object` 类的本地方法。

13. 为什么 wait() 方法不定义在 Thread 中？

	`wait()` 是让获得对象锁的线程实现等待，会自动释放当前线程占有的对象锁。每个对象（`Object`）都拥有对象锁，既然要释放当前线程占有的对象锁并让其进入 WAITING 状态，自然是要操作对应的对象（`Object`）而非当前的线程（`Thread`）。

14. **为什么 `sleep()` 方法定义在 `Thread` 中？**

	因为 `sleep()` 是让当前线程暂停执行，不涉及到对象类，也不需要获得对象锁。

15. 可以直接调用 Thread 类的 run 方法吗？

	new 一个 `Thread`，线程进入了新建状态。调用 `start()`方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。 `start()` 会执行线程的相应准备工作，然后自动执行 `run()` 方法的内容，这是真正的多线程工作。 但是，直接执行 `run()` 方法，会把 `run()` 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。

	**总结：调用 `start()` 方法方可启动线程并使线程进入就绪状态，直接执行 `run()` 方法的话不会以多线程的方式执行。**

16. volatile作用

	**`volatile` 关键字除了可以保证变量的可见性，还有一个重要的作用就是防止 JVM 的指令重排序。**

17. 乐观锁

	乐观锁总是假设最好的情况，认为共享资源每次被访问的时候不会出现问题，线程可以不停地执行，无需加锁也无需等待，只是在提交修改的时候去验证对应的资源（也就是数据）是否被其它线程修改了（具体方法可以使用版本号机制或 CAS 算法）。

	高并发的场景下，乐观锁相比悲观锁来说，不存在锁竞争造成线程阻塞，也不会有死锁的问题，在性能上往往会更胜一筹。但是，如果冲突频繁发生（写占比非常多的情况），会频繁失败和重试，这样同样会非常影响性能，导致 CPU 飙升。

	不过，大量失败重试的问题也是可以解决的，像我们前面提到的 `LongAdder`以空间换时间的方式就解决了这个问题。

18. 悲观锁

	悲观锁总是假设最坏的情况，认为共享资源每次被访问的时候就会出现问题(比如共享数据被修改)，所以每次在获取资源操作的时候都会上锁，这样其他线程想拿到这个资源就会阻塞直到锁被上一个持有者释放。也就是说，**共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程**。（Java 中`synchronized`和`ReentrantLock`等独占锁就是悲观锁思想的实现。）

19. 如何实现乐观锁？

	乐观锁一般会使用版本号机制或 CAS 算法实现，CAS 算法相对来说更多一些，这里需要格外注意。

	- 版本号机制：一般是在数据表中加上一个数据版本号 `version` 字段，表示数据被修改的次数。当数据被修改时，`version` 值会加一。当线程 A 要更新数据值时，在读取数据的同时也会读取 `version` 值，在提交更新时，若刚才读取到的 version 值为当前数据库中的 `version` 值相等时才更新，否则重试更新操作，直到更新成功。

	- CAS算法：CAS 的全称是 **Compare And Swap（比较与交换）** ，用于实现乐观锁，被广泛应用于各大框架中。CAS 的思想很简单，就是用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。

		CAS 是一个原子操作，底层依赖于一条 CPU 的原子指令。

		CAS 涉及到三个操作数：

		- **V**：要更新的变量值(Var)
		- **E**：预期值(Expected)
		- **N**：拟写入的新值(New)

		当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新。

20. 乐观锁存在的问题？

	ABA 问题是乐观锁最常见的问题。

21. ABA问题

	如果一个变量 V 初次读取的时候是 A 值，并且在准备赋值的时候检查到它仍然是 A 值，那我们就能说明它的值没有被其他线程修改过了吗？很明显是不能的，因为在这段时间它的值可能被改为其他值，然后又改回 A，那 CAS 操作就会误认为它从来没有被修改过。这个问题被称为 CAS 操作的 **"ABA"问题。**

	ABA 问题的解决思路是在变量前面追加上**版本号或者时间戳**。

22. synchronized的作用？

	`synchronized` 是 Java 中的一个关键字，翻译成中文是同步的意思，主要解决的是多个线程之间访问资源的同步性，可以保证被它修饰的方法或者代码块在任意时刻只能有一个线程执行。

23. synchronized关键字的3种使用方式

	- **修饰实例方法** （锁当前对象实例）

		给当前对象实例加锁，进入同步代码前要获得 **当前对象实例的锁** 。

	```java
	synchronized void method() {
	    //业务代码
	}
	```

	- **修饰静态方法** （锁当前类）

	给当前类加锁，会作用于类的所有对象实例 ，进入同步代码前要获得 **当前 class 的锁**。

	这是因为静态成员不属于任何一个实例对象，归整个类所有，不依赖于类的特定实例，被类的所有实例共享。

	```java
	synchronized static void method() {
	    //业务代码
	}
	```

	静态 `synchronized` 方法和非静态 `synchronized` 方法之间的调用互斥么？不互斥！如果一个线程 A 调用一个实例对象的非静态 `synchronized` 方法，而线程 B 需要调用这个实例对象所属类的静态 `synchronized` 方法，是允许的，不会发生互斥现象，因为访问静态 `synchronized` 方法占用的锁是当前类的锁，而访问非静态 `synchronized` 方法占用的锁是当前实例对象锁。

	- **修饰代码块** （锁指定对象/类）

		对括号里指定的对象/类加锁：

		- `synchronized(object)` 表示进入同步代码库前要获得 **给定对象的锁**。
		-  `synchronized(类.class)` 表示进入同步代码前要获得 **给定 Class 的锁**

	```java
	synchronized(this) {
	    //业务代码
	}
	```

	**总结：**

	- `synchronized` 关键字加到 `static` 静态方法和 `synchronized(class)` 代码块上都是是给 Class 类上锁；
	- `synchronized` 关键字加到实例方法上是给对象实例上锁；
	- 尽量不要使用 `synchronized(String a)` 因为 JVM 中，字符串常量池具有缓存功能。

24. 构造方法可以使用synchronized修饰么？

	**构造方法不能使用 synchronized 关键字修饰。**构造方法本身就属于线程安全的，不存在同步的构造方法一说。

25. synchronized 和 volatile 有什么区别？

	`synchronized` 关键字和 `volatile` 关键字是两个互补的存在，而不是对立的存在！

	- `volatile` 关键字是线程同步的轻量级实现，所以 `volatile`性能肯定比`synchronized`关键字要好 。但是 `volatile` 关键字只能用于变量而 `synchronized` 关键字可以修饰方法以及代码块 。
	- `volatile` 关键字能保证数据的可见性，但不能保证数据的原子性。`synchronized` 关键字两者都能保证。
	- `volatile`关键字主要用于解决变量在多个线程之间的可见性，而 `synchronized` 关键字解决的是多个线程之间访问资源的同步性。

26. 公平锁和非公平锁

	**公平锁** : 锁被释放之后，先申请的线程先得到锁。性能较差一些，因为公平锁为了保证时间上的绝对顺序，上下文切换更频繁。

	**非公平锁**：锁被释放之后，后申请的线程可能会先获取到锁，是随机或者按照其他优先级排序的。性能更好，但可能会导致某些线程永远无法获取到锁。

27. 可中断锁和不可中断锁有什么区别？

	- **可中断锁**：获取锁的过程中可以被中断，不需要一直等到获取锁之后 才能进行其他逻辑处理。`ReentrantLock` 就属于是可中断锁。
	- **不可中断锁**：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。 `synchronized` 就属于是不可中断锁。

28. 共享锁和独占锁有什么区别？

	- **共享锁**：一把锁可以被多个线程同时获得。
	- **独占锁**：一把锁只能被一个线程获得。

29. 线程持有读锁还能获取写锁吗？

	在线程持有读锁的情况下，该线程不能取得写锁(因为获取写锁的时候，如果发现当前的读锁被占用，就马上获取失败，不管读锁是不是被当前线程持有)。

	在线程持有写锁的情况下，该线程可以继续获取读锁（获取读锁时如果发现写锁被占用，只有写锁没有被当前线程占用的情况才会获取失败）。

30. 读锁为什么不能升级为写锁？

	写锁可以降级为读锁，但是读锁却不能升级为写锁。这是因为读锁升级为写锁会引起线程的争夺，毕竟写锁属于是独占锁，这样的话，会影响性能。

	另外，还可能会有死锁问题发生。举个例子：假设两个线程的读锁都想升级写锁，则需要对方都释放自己锁，而双方都不释放，就会产生死锁。

31. ReentrantLock 是什么？

	`ReentrantLock` 实现了 `Lock` 接口，是一个可重入且独占式的锁，和 `synchronized` 关键字类似。不过，`ReentrantLock` 更灵活、更强大，增加了轮询、超时、中断、公平锁和非公平锁等高级功能。（`ReentrantLock` 的底层就是由 AQS 来实现的。）

32. 自旋锁

	Java自旋锁是一种基于“忙等待”的锁，它通过不断地重试来获取锁，而不是像传统的互斥锁那样进入阻塞状态。它的实现方式是在代码中使用while循环不断尝试获取锁，直到成功为止。

	Java中提供了两种自旋锁的实现方式：基于synchronized关键字的自旋锁和基于Atomic类的自旋锁。

	其中，基于synchronized关键字的自旋锁可以通过使用synchronized关键字的wait()和notify()方法实现。具体来说，当线程尝试获取锁时，如果失败了，就会调用wait()方法使自己进入等待状态，并释放锁；而当其他线程释放了锁后，会调用notify()方法唤醒正在等待的线程。这样，被唤醒的线程就可以再次尝试获取锁，从而避免了阻塞和唤醒的开销。

	而基于Atomic类的自旋锁则是利用CAS（Compare and Set）指令来实现的。具体来说，它通过不断地比较当前变量的值和期望的值，如果相同就更新变量的值，否则继续重试。由于CAS操作是原子性的，并且不会导致线程进入阻塞状态，因此可以实现更高效的自旋锁。

	需要注意的是，自旋锁适用于锁竞争不激烈的情况，并且要求被锁定的代码块执行时间尽可能短。如果锁竞争非常激烈，或者被锁定的代码块执行时间过长，那么使用自旋锁反而会降低程序的性能。此外，由于自旋锁需要占用CPU资源，因此也需要慎重选择使用时机。

33. 适应性自旋锁

	Java中的适应性自旋锁是一种智能型自旋锁，它能够根据当前线程在临界区内的等待时间来动态地调整自旋次数，从而避免了长时间的自旋和不必要的开销。具体来说，适应性自旋锁会监测上次获取锁的时间、自旋次数以及线程的状态等信息，将这些信息作为参考，决定当前线程是否需要进行自旋，以及自旋的次数。

	适应性自旋锁的实现基于Java虚拟机提供的LockSupport类，它可以精确控制线程的阻塞和唤醒操作，从而实现高效的线程同步。具体来说，当一个线程尝试获取锁时，如果失败了，它会进入阻塞状态，并通过LockSupport类的park()方法来挂起自己。而当其他线程释放了锁后，它们会通过LockSupport类的unpark()方法来唤醒正在等待的线程。同时，适应性自旋锁还会记录当前线程的状态（是否处于阻塞状态）、自旋次数以及上次获取锁的时间等信息，通过动态调整自旋次数和自旋时间来适应当前的环境。

	需要注意的是，适应性自旋锁是一种比较高级的锁技术，它能够根据当前环境动态地调整自旋次数和自旋时间，从而提高程序的性能。但它也不是适用于所有情况的，如果在低竞争的情况下使用，反而会浪费CPU资源。因此，在使用适应性自旋锁时，需要进行实际的性能测试，并根据实际情况进行选择。

34. 锁消除

	Java中的锁消除是一种针对部分同步代码块的优化技术，它可以在编译时通过静态分析的方式判断同步代码块是否会发生线程竞争，并在不需要同步保护的情况下自动将其消除，从而减少程序的开销。

	具体来说，当Java编译器发现一个同步代码块只被单个线程所访问，并且没有共享数据的情况下，就会自动将该同步代码块消除掉。这样，在运行时就不需要进行同步保护，从而避免了锁的竞争和开销。

	需要注意的是，锁消除虽然可以提高程序的性能，但并不适用于所有情况。例如，在多线程环境下，如果同步代码块中存在共享数据，即使只有一个线程访问该共享数据，也仍然需要进行同步保护，否则可能会导致数据出错或线程安全问题。因此，在使用锁消除技术时，必须仔细分析代码的实际情况，并进行实际测试，以确保程序的正确性和稳定性。

	另外，需要注意的是，锁消除只能消除对象锁（synchronized关键字），无法消除其他类型的锁，如ReentrantLock等。因此，在使用其他类型的锁时，需要特别注意锁的使用方式和实现细节。

35. 锁粗化

	Java中的锁粗化是一种针对连续的同步操作进行优化的技术，它可以将多个连续的同步操作合并为一个大的同步块，从而减少线程获取和释放锁的次数，提高程序的性能。

	具体来说，当Java编译器发现程序中存在一些连续的同步代码块，并且它们之间没有共享数据的情况下，就可以将它们合并为一个大的同步块，这样就可以减少线程获取和释放锁的次数。例如，下面的代码中就存在多个连续的同步代码块：

	```
	javaCopy Codesynchronized (lock) {
	    // do something
	}
	synchronized (lock) {
	    // do something else
	}
	synchronized (lock) {
	    // do another thing
	}
	```

	在这种情况下，就可以将这些同步块合并为一个大的同步块：

	```
	javaCopy Codesynchronized (lock) {
	    // do something
	    // do something else
	    // do another thing
	}
	```

	这样，在运行时就只需要获取和释放一次锁，从而提高程序的性能。

	需要注意的是，锁粗化只适用于同步块之间没有共享数据的情况下。如果同步块之间存在共享数据，那么就无法进行锁粗化优化，因为这样做可能会导致数据出错或线程安全问题。因此，在使用锁粗化技术时，必须仔细分析代码的实际情况，并进行实际测试，以确保程序的正确性和稳定性。

36. 偏向锁

	偏向锁是Java中的一种优化机制，它针对不存在竞争的情况下优化同步操作。在JVM启动的时候，偏向锁是默认开启的。

	偏向锁的原理是，当一个线程访问一个同步块时，如果该锁没有被其他线程占用，则该线程会通过CAS操作将对象头设置为偏向锁，并且将当前线程ID存储在对象头中，表示该锁被该线程所占用。当其他线程再次访问该锁时，会先检查对象头中的线程ID是否与自己的线程ID相同，如果相同，则认为该锁无竞争，直接进入同步块执行；否则，可能存在竞争，需要使用其他方式（如轻量级锁和重量级锁）来保证同步。

	偏向锁的优点是，当多个线程访问同一个同步块而不存在竞争时，可以避免二次加锁带来的额外开销，从而提高程序的性能和响应速度。它适用于大部分情况下存在单线程访问同步块的场景，例如Java中的synchronized关键字。

	需要注意的是，偏向锁只适用于没有竞争的情况下。如果同步块被多个线程频繁地访问，那么偏向锁的开销可能会超过正常的加锁和解锁操作，从而降低程序的性能。此外，由于偏向锁需要存储线程ID等额外信息，因此在大量使用同步块的情况下，也可能导致内存占用过高的问题。因此，在使用偏向锁时，需要根据实际情况进行选择，并进行实际测试，以确保程序的正确性和稳定性。

37. ThreadLocal

	ThreadLocal，即线程本地变量。一个共享变量存进该容器相当于在线程内部拷贝了一个副本。ThreadLocal里面的变量都是存在当前线程的。当操作ThreadLocal里面的变量时，实际操作的是存在自己线程的那个变量副本，该变量副本对于每一个线程都是独立的，从而实现了变量的隔离性，保证了线程安全。

38. TheadLocal原理

	ThreadLocal是Java提供的一种线程封闭机制，它可以在每个线程中维护一个独立的变量副本。这样，不同线程访问该变量时就不会产生冲突。

	ThreadLocal的原理非常简单，它实际上是通过在Thread类中使用一个Map来保存每个线程对应的变量副本。具体来说，当程序调用ThreadLocal的set()方法时，ThreadLocal会先获取当前线程对象，然后将变量值存入该线程对象对应的Map中；而当程序调用ThreadLocal的get()方法时，ThreadLocal同样会先获取当前线程对象，然后从该线程对象对应的Map中获取变量值。

	因为每个线程都有自己的Map，所以即使多个线程同时操作同一个ThreadLocal对象，它们也不会互相影响。这就保证了线程安全性。另外，由于ThreadLocal是在每个线程中维护一个独立的变量副本，所以即使在线程之间传递对象，也不会产生共享变量的问题。这样可以有效地减少锁竞争，提高程序的并发性能。

	需要注意的是，使用ThreadLocal时要特别注意内存泄漏的问题。因为每个线程都持有一个对应的变量副本，如果不及时清理，可能会导致内存占用过高。所以在使用完ThreadLocal后，一定要及时调用它的remove()方法，将对应的变量副本从当前线程的Map中删除。

39. ThreadLocal 内存泄露问题是怎么导致的？

	- ThreadLocal 内存泄露问题通常是由于线程池或者其他长生命周期的对象持有 ThreadLocal 变量导致的。

		具体来说，ThreadLocal 是基于线程的变量，每个 ThreadLocal 变量都会与某个线程关联。当线程结束时，如果没有手动清除 ThreadLocal 变量，该线程所持有的所有 ThreadLocal 变量都会被 GC 回收。

		然而，如果某些对象在实现时使用了线程池等长生命周期的对象，那么 ThreadLocal 对象就可能被长期持有，从而导致内存泄漏。因为线程池中的线程不会像单独的线程一样轻易结束，这就意味着它们持有的 ThreadLocal 变量也不会被及时回收。

		另外，如果在使用 ThreadLocal 时没有正确地使用 try-finally 块来清理变量，也可能导致内存泄漏。这样做会使得 ThreadLocal 变量无法被正确地清除，从而导致内存泄漏。

		为了避免 ThreadLocal 内存泄漏问题，需要注意以下几点：

		1. 在使用线程池时，必须确保在任务执行完毕后手动清除 ThreadLocal 变量；
		2. 在使用 ThreadLocal 变量时，必须始终使用 try-finally 块来确保变量能够被正确地清理；
		3. 评估线程池使用情况，避免在线程池中长期存储 ThreadLocal 变量。

	- 从源码角度来看，ThreadLocal 内存泄漏的问题是由于 ThreadLocalMap 中的 Entry 引用了 ThreadLocal 实例对象，而这个引用没有被及时回收导致的。具体来说，ThreadLocalMap 是一个以 ThreadLocal 为键，以线程局部变量的值为值的数据结构。当一个线程结束时，它会将自己所持有的所有 ThreadLocalMap.Entry 都清除掉，但是如果在调用 remove() 方法之前，其对应的 ThreadLocal 实例被垃圾回收器回收了，那么这个 Entry 就会产生内存泄漏。

		下面是 ThreadLocalMap 的部分代码实现：

		```
		Copy Codestatic class Entry extends WeakReference<ThreadLocal<?>> {
		    Object value;
		
		    Entry(ThreadLocal<?> k, Object v) {
		        super(k);
		        value = v;
		    }
		}
		
		private Entry[] table;
		
		private void set(ThreadLocal<?> key, Object value) {
		
		    // 省略了一些扩容和处理 hash 冲突的逻辑
		
		    int i = firstEmptySlot();
		
		    table[i] = new Entry(key, value);
		    size++;
		
		    // 进行 expungeStaleEntries 操作
		    expungeStaleEntries();
		}
		```

		在上述代码中，ThreadLocalMap.Entry 继承了 WeakReference<ThreadLocal<?>> 类，它使用弱引用来引用 ThreadLocal 对象。这样的设计是为了避免 ThreadLocal 被 Table 强引用而无法被回收。而 expungeStaleEntries() 方法会检测 Entry 中的 ThreadLocal 引用是否为 null，如果为 null 则说明 ThreadLocal 已经被回收，这时就需要将 Entry 从 table 中移除。

		但是，如果线程一直没有结束，ThreadLocalMap 中的 Entry 就会一直存在，并且仍然引用着对应的 ThreadLocal 对象，从而导致内存泄漏。因此，在使用 ThreadLocal 时，我们需要特别注意确保在不再需要使用该变量时及时调用 remove() 方法，以便让 ThreadLocalMap 中的 Entry 也能被正确回收。

40. 什么是线程池？

	顾名思义，线程池就是管理一系列线程的资源池。当有任务要处理时，直接从线程池中获取线程来处理，处理完之后线程并不会立即被销毁，而是等待下一个任务。

41. 为什么要使用线程池？

	池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。

	**降低资源消耗**。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。

	**提高响应速度**。当任务到达时，任务可以不需要等到线程创建就能立即执行。

	**提高线程的可管理性**。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。

42. AQS原理？

	AQS（AbstractQueuedSynchronizer）是Java中用于实现同步器的基础类，例如ReentrantLock和Semaphore都是基于AQS来实现的。

	AQS基于队列等待线程访问共享资源，并提供了一些方法来管理等待队列和同步状态。它的核心思想是使用一个volatile类型的int变量作为同步状态，表示当前共享资源被占用的情况。当一个线程需要访问共享资源时，它会首先尝试获取同步状态。如果同步状态为空闲，则线程可以直接获得共享资源并将同步状态设置为占用；否则，线程将被加入到等待队列中，等待其他线程释放共享资源，并唤醒队列中的下一个线程以获取共享资源。

	在AQS中，实际上是通过内部维护一个双向的FIFO队列，来实现线程的等待和唤醒操作。当一个线程加入等待队列后，它会进入休眠状态，只有当前面的线程释放了锁或者同步状态时，该线程才会被唤醒。

	此外，AQS还提供了对于锁、信号量等常见同步工具的支持，通过子类化AQS并实现其中的acquire()、tryRelease()等方法，就可以构建各种不同的同步工具。

	总之，AQS的原理其实就是基于同步状态和等待队列来实现线程的同步和互斥访问，通过一些精妙的算法和数据结构来管理等待队列，从而实现高效、可重入的同步机制。







## 参考文档

https://mp.weixin.qq.com/s/R5MrTsWvk9McFSQ7bS0W2w

[ThreadLocal原理总结](https://blog.csdn.net/m0_57713282/article/details/123887036)